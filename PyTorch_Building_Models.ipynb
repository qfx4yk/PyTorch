{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+BOiG3mBxAGuWe3YzjQRH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qfx4yk/PyTorch/blob/main/PyTorch_Building_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Building the Neural Network\n",
        "\n",
        "Neural networks comprise of layers/modules that perform operations on data. The torch.nn namespace provides all the building blocks you need to build your own neural network. Every module in PyTorch subclasses the nn.Module. A neural network is a module itself that consists of other modules (layers). This nested structure allows for building and managing complex architectures easily."
      ],
      "metadata": {
        "id": "KvcGw202w-iT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lM3hOwvQ3jpZ"
      },
      "outputs": [],
      "source": [
        "import torch # for all things PyTorch\n",
        "import torch.nn as nn # for torch.nn.Module, the parent object for PyTorch models;\n",
        "# contains the neural network layers that we are going to compose into our model as well as the parent class of the model itself\n",
        "import torch.nn.functional as F # for the activation functions and max pooling functions we can use to connect the layers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LeNet-5\n",
        "\n",
        "LeNet-5 is one of the earliest convolutional neural networks and one of the drivers of the explosion in deep learning. It was built to read small images of handwritten numbers (the MNIST dataset) and correctly classified which digit was represented in the image.\n",
        "\n",
        "Here is an abdriged version of how it works:\n",
        "\n",
        "\n",
        "\n",
        "*   Layer C1 is a convolutional layer, meaning that it scans the input image for features it learned during training. It outputs a map of where it saw each of its learned features in the image. This \"activation map\" is downsampled in layer S2.\n",
        "*   Layer C3 is another convolutional layer, this time scanning C1's activation map for combinations of features. It also puts out an activation map describing the spatial locations of these feature combinations, which is downsampled in layer S4.\n",
        "*   Finally, the fully-connected layers at the end, F5, F6, and OUTPUT, are a classifier that takes the final activation map, and classifies it into one of ten bind representing the 10 digits.  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F4fXHruW5Be8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LeNet, self).__init__()\n",
        "    # 1 input image channel (black & white), 6 output channels, 3x3 square convolution\n",
        "    # kernel\n",
        "    self.conv1 = nn.Conv2d(1,6,3)\n",
        "    self.conv2 = nn.Conv2d(6,16,3)\n",
        "    # an affine operation: y = Wx + b\n",
        "    self.fc1 = nn.Linear(16*6*6, 120) # 6*6 from image dimension\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Max pooling over a (2,2) window\n",
        "    x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
        "    # If the size is a square you can only specify a single number\n",
        "    x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "    x = x.view(-1, self.num_flat_features(x))\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "  def num_flat_features(self, x):\n",
        "    size = x.size()[1:] # all dimensions except the batch dimension\n",
        "    num_features = 1\n",
        "    for s in size:\n",
        "      num_features *= s\n",
        "    return num_features"
      ],
      "metadata": {
        "id": "oQpG0jQ37qT6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code above represents the structure of a typical PyTorch model:\n",
        "1. It inherits from torch.nn.Module and modules may be nested. In fact, even the Conv2d and Linear layers are subclasses of torch.nn.Module.\n",
        "2. Every model will have an __init__ where it constructs the layers that it will compose into its computation graph and loads any data artifacts it might need (e.g. an NLP model might load a vocabulary).\n",
        "3. A model will have a forward() function. This is where the actual computation happens. An input is passed through the network layers and various functions to generate an output (prediction).\n",
        "4. In addition, you can build your model class like any other Python class, adding whatever properties and methods you need to support your model's computation."
      ],
      "metadata": {
        "id": "wRBk1rkD7zAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Running a sample input thru the model above\n",
        "net = LeNet()\n",
        "print(net)\n",
        "\n",
        "input = torch.randn(1,1,32,32)\n",
        "print('\\nImage batch shape:')\n",
        "print(input.shape)\n",
        "\n",
        "output = net(input)\n",
        "print('\\nRaw output:')\n",
        "print(output)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEdxfUhFTwZM",
        "outputId": "714b27c4-f4d7-4b5b-ecae-7c802455f75f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LeNet(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "\n",
            "Image batch shape:\n",
            "torch.Size([1, 1, 32, 32])\n",
            "\n",
            "Raw output:\n",
            "tensor([[-0.0749, -0.0541, -0.1712, -0.1167, -0.0448, -0.0576, -0.1349,  0.0034,\n",
            "          0.1703, -0.0719]], grad_fn=<AddmmBackward0>)\n",
            "torch.Size([1, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we create an instance of LeNet, and we print the net object. A subclass of torch.nn.Module will report the layers it has created and their shapes and parameters. This can provide a handy overview of a model if you want to get the gist of its processing.\n",
        "\n",
        "Then, we creare a dummy input representing a 32x32 image with 1 color channel. Normally, you would load an image tile and convert it to a tensor of this shape.There is an extra dimension in the tensor - the *batch* dimension. PyTorch models assume they are working on *batches* of data. For example: a batch of 16 of our image tiles would have the shape (16, 1, 32, 32). Since we are only using one image, we create a batch of 1 with shape (1,1,32,32).\n",
        "\n",
        "We ask the model for an inference by calling it like a function: net(input). The output of this call represents the model's confidence that the input represents a particular digit. (Since this instance of the model has not learned anything yet, we should not expect to see any signal in the output.). Looking at the shape of the output, we can see that it also has a batch dimension the size of which should always match the input batch dimension."
      ],
      "metadata": {
        "id": "4pintgbGUCMr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network for FashionMNIST"
      ],
      "metadata": {
        "id": "bmhYiTYpxozU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "u77IG8hZxv8a"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Device for Training\n",
        "\n",
        "We want to be able to train our model on a hardware accelerator like the GPU or MPS, if available. Let’s check to see if torch.cuda or torch.backends.mps are available, otherwise we use the CPU."
      ],
      "metadata": {
        "id": "JF51VraVyJuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llQYfP48yNli",
        "outputId": "a720bf5c-352a-46bd-b624-d081b1da8437"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Class\n",
        "\n",
        "We define our neural network by subclassing nn.Module, and initialize the neural network layers in __init__. Every nn.Module subclass implements the operations on input data in the forward method."
      ],
      "metadata": {
        "id": "rHHRhzlbyP-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "olCgW6h8yxOa"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We create an instance of NeuralNetwork, and move it to the device, and print its structure.\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJcOQF8ry83S",
        "outputId": "aa0b33c5-d620-4388-fd49-98725ad53cf5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note: To use the model, we pass it the input data. This executes the model’s forward, along with some background operations. Do not call model.forward() directly!**"
      ],
      "metadata": {
        "id": "8T84lxqEzi5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.rand(1, 28, 28, device=device)\n",
        "logits = model(X)\n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "print(f\"Predicted class: {y_pred}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sinD05izzYD",
        "outputId": "706d98d6-ce5a-4dd9-93e8-1ddfd0b0d14d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: tensor([4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calling the model on the input returns a 2-dimensional tensor with dim=0 corresponding to each output of 10 raw predicted values for each class, and dim=1 corresponding to the individual values of each output. We get the prediction probabilities by passing it through an instance of the nn.Softmax module."
      ],
      "metadata": {
        "id": "ZvcMaouoz7-S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Layers"
      ],
      "metadata": {
        "id": "JMlj7gYW0Q-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We will take a sample minibatch of 3 images of size 28x28\n",
        "input_image = torch.rand(3,28,28)\n",
        "print(input_image.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLA7ni2t0Irq",
        "outputId": "13b4daae-2fb1-4334-84b2-34130e5a4153"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### nn.Flatten"
      ],
      "metadata": {
        "id": "41Z11MPx0i1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We initialize the nn.Flatten layer to convert each 2D 28x28 image into a contiguous array of 784 pixel values\n",
        "flatten = nn.Flatten()\n",
        "flat_image = flatten(input_image)\n",
        "print(flat_image.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UP-4F_9V0g16",
        "outputId": "5619635d-e4e6-4476-eefc-b67be3c8a5e9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 784])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### nn.Linear"
      ],
      "metadata": {
        "id": "sv-dLve81mNT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The linear layer is a module that applies a linear transformation on the input using its stored weights and biases\n",
        "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
        "hidden1 = layer1(flat_image)\n",
        "print(hidden1.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaVV-CPl1n9i",
        "outputId": "535fadf4-57e3-4506-d476-525c363495b5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### nn.ReLU\n",
        "\n",
        "Non-linear activations are what create the complex mappings between the model’s inputs and outputs. They are applied after linear transformations to introduce nonlinearity, helping neural networks learn a wide variety of phenomena.\n",
        "\n",
        "In this model, we use nn.ReLU between our linear layers, but there’s other activations to introduce non-linearity in your model."
      ],
      "metadata": {
        "id": "LW8hpUWJ2IXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
        "hidden1 = nn.ReLU()(hidden1)\n",
        "print(f\"After ReLU: {hidden1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nr0zJgcE2O_D",
        "outputId": "5a6ad9ff-4b44-4aa2-f7e3-0232e107ac12"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before ReLU: tensor([[-0.2255,  0.3069, -0.4549,  0.1189,  0.2371,  0.9187,  0.5445, -0.1907,\n",
            "          0.3097,  0.3343, -0.4944, -0.0820, -0.3132,  0.5316,  0.0838, -0.0755,\n",
            "         -0.2348, -0.2486,  0.2889, -0.7953],\n",
            "        [ 0.1777,  0.4944, -0.7440,  0.0620,  0.0016,  0.4225,  0.0955, -0.2760,\n",
            "         -0.2505,  0.3827, -0.3239, -0.0269, -0.7322,  0.8209,  0.2649, -0.0144,\n",
            "         -0.3590, -0.0383,  0.2358, -0.5863],\n",
            "        [ 0.1774,  0.6033, -0.7095,  0.1282,  0.1001,  0.3616,  0.1147, -0.0727,\n",
            "          0.0123,  0.2914, -0.1166, -0.1367, -0.3130,  0.6286,  0.1271, -0.0160,\n",
            "         -0.3586, -0.2379,  0.1306, -0.5698]], grad_fn=<AddmmBackward0>)\n",
            "\n",
            "\n",
            "After ReLU: tensor([[0.0000, 0.3069, 0.0000, 0.1189, 0.2371, 0.9187, 0.5445, 0.0000, 0.3097,\n",
            "         0.3343, 0.0000, 0.0000, 0.0000, 0.5316, 0.0838, 0.0000, 0.0000, 0.0000,\n",
            "         0.2889, 0.0000],\n",
            "        [0.1777, 0.4944, 0.0000, 0.0620, 0.0016, 0.4225, 0.0955, 0.0000, 0.0000,\n",
            "         0.3827, 0.0000, 0.0000, 0.0000, 0.8209, 0.2649, 0.0000, 0.0000, 0.0000,\n",
            "         0.2358, 0.0000],\n",
            "        [0.1774, 0.6033, 0.0000, 0.1282, 0.1001, 0.3616, 0.1147, 0.0000, 0.0123,\n",
            "         0.2914, 0.0000, 0.0000, 0.0000, 0.6286, 0.1271, 0.0000, 0.0000, 0.0000,\n",
            "         0.1306, 0.0000]], grad_fn=<ReluBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### nn.Sequential"
      ],
      "metadata": {
        "id": "ogo2nwUj2vH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# nn.Sequential is an ordered container of modules. The data is passed through all the modules in the same order as defined.\n",
        "seq_modules = nn.Sequential(\n",
        "    flatten,\n",
        "    layer1,\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20, 10)\n",
        ")\n",
        "input_image = torch.rand(3,28,28)\n",
        "logits = seq_modules(input_image)"
      ],
      "metadata": {
        "id": "rIv9OY-F2qj6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### nn.Softmax\n",
        "\n",
        "The last linear layer of the neural network returns logits - raw values in [-infty, infty] - which are passed to the nn.Softmax module. The logits are scaled to values [0, 1] representing the model’s predicted probabilities for each class. dim parameter indicates the dimension along which the values must sum to 1."
      ],
      "metadata": {
        "id": "dpBN4rzH3VJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "softmax = nn.Softmax(dim=1)\n",
        "pred_probab = softmax(logits)"
      ],
      "metadata": {
        "id": "M_lMGxDS3cJe"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Parameters\n",
        "\n",
        "Many layers inside a neural network are parameterized, i.e. have associated weights and biases that are optimized during training. Subclassing nn.Module automatically tracks all fields defined inside your model object, and makes all parameters accessible using your model’s parameters() or named_parameters() methods."
      ],
      "metadata": {
        "id": "cGHPOvWXBrrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterating over each paramter and printing its size and a preview of its values\n",
        "print(f\"Model structure: {model}\\n\\n\")\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_r6Su1mB_41",
        "outputId": "acfd9970-b83f-4a94-fd39-0933446f37d0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model structure: NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "\n",
            "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[-0.0212,  0.0320, -0.0260,  ..., -0.0205,  0.0037, -0.0315],\n",
            "        [ 0.0030, -0.0328,  0.0037,  ...,  0.0293, -0.0042, -0.0185]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([-0.0096,  0.0020], grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0116, -0.0165, -0.0098,  ...,  0.0404, -0.0134, -0.0062],\n",
            "        [ 0.0307, -0.0307,  0.0260,  ..., -0.0268, -0.0049, -0.0070]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([0.0144, 0.0254], grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[ 0.0349,  0.0001, -0.0334,  ..., -0.0333,  0.0220,  0.0139],\n",
            "        [ 0.0033,  0.0044, -0.0081,  ...,  0.0120, -0.0442, -0.0116]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([0.0395, 0.0170], grad_fn=<SliceBackward0>) \n",
            "\n"
          ]
        }
      ]
    }
  ]
}